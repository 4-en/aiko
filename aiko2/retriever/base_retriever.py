from aiko2.core import Conversation, Message
from abc import ABC, abstractmethod
from .retrieval_results import RetrievalResults
import sentence_transformers
import numpy as np
import rank_bm25


class BaseRetriever(ABC):
    """
    Base class for a retriever.
    A retriever retrieves information based on the queries generated by the evaluator.
    """
    
    
    @abstractmethod
    def retrieve(self, conversation:Conversation, queries:list[str]) -> RetrievalResults:
        """
        Retrieve information based on the queries generated by the evaluator.
        
        Parameters
        ----------
        conversation : Conversation
            The conversation to retrieve information for.
        queries : List[str]
            A list of queries to retrieve information.
        
        Returns
        -------
        RetrievalResults
            The retrieval context containing the results of the retrieval operation.
        """
        pass
    
    _sentence_transformer_model = None
    
    @property
    def model() -> sentence_transformers.SentenceTransformer:
        """
        Get the sentence transformer model.
        """
        if not BaseRetriever._sentence_transformer_model:
            BaseRetriever._sentence_transformer_model = sentence_transformers.SentenceTransformer('paraphrase-MiniLM-L6-v2')
        return BaseRetriever._sentence_transformer_model
    
    def embed(text:str) -> np.ndarray:
        """
        Embed a text into a vector.
        
        Parameters
        ----------
        text : str
            The text to embed.
        
        Returns
        -------
        np.ndarray
            The embedded text as a vector.
        """
        tensor = BaseRetriever.model.encode(text)
        return tensor.numpy()
    
    def calculate_similarity(embedding1:np.ndarray, embedding2:np.ndarray, metric:str='cosine') -> float:
        """
        Calculate the similarity between two embeddings.
        
        Parameters
        ----------
        embedding1 : np.ndarray
            The first embedding.
        embedding2 : np.ndarray
            The second embedding.
        metric : str, optional
            The metric to use for calculating the similarity. The default is 'cosine'.
        
        Returns
        -------
        float
            The similarity between the two embeddings.
        """
        if metric == 'cosine':
            return np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))
        else:
            raise ValueError(f"Unsupported metric: {metric}")
        
    def bm25_rank_results(query:str, results:list[str]) -> list[tuple[str, float]]:
        """
        Rank the results based on the similarity to the query using BM25.
        
        Parameters
        ----------
        query : str
            The query to rank the results against.
        results : List[str]
            The list of results to rank.
        
        Returns
        -------
        List[Tuple[str, float]]
            A list of tuples containing the result and its similarity to the query.
        """
        bm25 = rank_bm25.BM25Okapi(results)
        
        # Tokenizing the query
        tokenized_query = query.lower().split()

        # Get BM25 scores
        scores = bm25.get_scores(tokenized_query)

        # Rank documents by score
        ranked_results = sorted(zip(results, scores), key=lambda x: x[1], reverse=True)
        return ranked_results
        
    def rank_results(query:str, results:list[str], metric:str='cosine') -> list[tuple[str, float]]:
        """
        Rank the results based on the similarity to the query.
        
        Parameters
        ----------
        query : str
            The query to rank the results against.
        results : List[str]
            The list of results to rank.
        metric : str, optional
            The metric to use for calculating the similarity. The default is 'cosine'.
        
        Returns
        -------
        List[Tuple[str, float]]
            A list of tuples containing the result and its similarity to the query.
        """
        query_embedding = BaseRetriever.embed(query)
        result_embeddings = [BaseRetriever.embed(result) for result in results]
        similarities = [BaseRetriever.calculate_similarity(query_embedding, result_embedding, metric) for result_embedding in result_embeddings]
        ranked_results = sorted(zip(results, similarities), key=lambda x: x[1], reverse=True)
        return ranked_results